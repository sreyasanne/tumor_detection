# -*- coding: utf-8 -*-
"""tumor_detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XaDg4i9yju_ovLvKGXkIbhhICWYbxtEZ
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Import necessary libraries
import os
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense
from tensorflow.keras.optimizers import Adam
import cv2
from PIL import Image

# Dataset paths
Root = "/content/drive/MyDrive/brain_tumor_dataset"
No_brain_tumor = os.path.join(Root, 'no')
Yes_brain_tumor = os.path.join(Root, 'yes')

# Load image file paths and labels
dirlist = [No_brain_tumor, Yes_brain_tumor]
classes = ['No', 'Yes']
filepaths = []
labels = []

for i, j in zip(dirlist, classes):
    filelist = os.listdir(i)
    for f in filelist:
        filepath = os.path.join(i, f)
        filepaths.append(filepath)
        labels.append(j)

# Create dataframe
df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})

# Visualize sample images
plt.figure(figsize=(10, 10))
for i in range(5):
    random = np.random.randint(1, len(df))
    plt.subplot(3, 5, i + 1)
    plt.imshow(cv2.imread(df.loc[random, "filepaths"]))
    plt.title(df.loc[random, "labels"], size=5, color="black")
    plt.axis("off")
plt.show()

# Split the dataset
from sklearn.model_selection import train_test_split

train, test = train_test_split(df, train_size=0.65, random_state=0)
train_new, valid = train_test_split(train, train_size=0.60, random_state=0)

# Print shapes of train, test, validation datasets
print(f"train set shape: {train_new.shape}")
print(f"test set shape: {test.shape}")
print(f"validation set shape: {valid.shape}")

# Data augmentation and image data generators
train_datagen = ImageDataGenerator(rescale=1./255., rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,
                                   shear_range=0.2, zoom_range=0.2, horizontal_flip=True, vertical_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255.)

# Create generators
train_gen = train_datagen.flow_from_dataframe(dataframe=train_new, x_col='filepaths', y_col='labels', target_size=(224, 224),
                                              batch_size=32, class_mode='binary', shuffle=True)
val_gen = train_datagen.flow_from_dataframe(dataframe=valid, x_col='filepaths', y_col='labels', target_size=(224, 224),
                                            batch_size=16, class_mode='binary', shuffle=True)
test_gen = test_datagen.flow_from_dataframe(dataframe=test, x_col='filepaths', y_col='labels', target_size=(224, 224),
                                            batch_size=16, class_mode='binary', shuffle=False)

# Load pre-trained ResNet50V2
base_model = tf.keras.applications.ResNet50V2(weights="imagenet", input_shape=(224, 224, 3), include_top=False)
base_model.trainable = False  # Freeze base model

# Build the new model
inputs = tf.keras.Input(shape=(224, 224, 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.2)(x)
outputs = Dense(1, activation="sigmoid")(x)
model = Model(inputs, outputs)

# Model summary
model.summary()

# Compile the model
callbacks = [
    tf.keras.callbacks.ModelCheckpoint("Tumor_classifier_model.keras", save_best_only=True, verbose=0)
]

model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Train the model
history = model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[callbacks], verbose=1)

# Save the model
model.save("/content/drive/MyDrive/brain_tumor_dataset/object_detection_model.keras")

# Plot training history
pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)
plt.show()

# Evaluate model performance on test set
from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(test_gen)
y_pred_labels = np.where(y_pred > 0.5, 1, 0)  # Binary classification (threshold 0.5)
y_true = test_gen.classes

print("Classification report:")
print(classification_report(y_true, y_pred_labels, target_names=['no tumor', 'tumor']))

print("Confusion matrix:")
cm = confusion_matrix(y_true, y_pred_labels)
print(cm)

# Fine-tune the model by unfreezing the last few layers of the base model
base_model.trainable = True
for layer in base_model.layers[:-10]:
    layer.trainable = False

model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-5), metrics=['accuracy'])
history = model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=[callbacks], verbose=1)

# Test with a new image
image_path = "/content/drive/MyDrive/brain_tumor_dataset/no/12 no.jpg"
image = cv2.imread(image_path)
image_fromarray = Image.fromarray(image, 'RGB')
resize_image = image_fromarray.resize((224, 224))

expand_input = np.expand_dims(resize_image, axis=0)
input_data = np.array(expand_input) / 255.0  # Normalize

# Load the model and make predictions
loaded_model = tf.keras.models.load_model("/content/drive/MyDrive/brain_tumor_dataset/object_detection_model.keras")
pred = loaded_model.predict(input_data)

# Predict the class
predicted_label = 'tumor' if pred[0][0] > 0.5 else 'no tumor'
print(f"Predicted class label: {predicted_label}")